**ğŸ§  Random Forest & Decision Tree Classifier - Model Optimization Project**

**Overview**

This repository showcases a hands-on machine learning project focused on building, evaluating, and optimizing Random Forest and Decision Tree classifiers. The objective was to implement a structured pipeline involving EDA, preprocessing, model training, and hyperparameter tuning to achieve a high-performing classification model.

**ğŸ“‚ Project Structure**

Exploratory Data Analysis (EDA): Uncovered key data trends and ensured feature readiness.

Preprocessing: Label encoding was applied to handle categorical variables.

**Model Training:**

**Random Forest Classifier**
Accuracy: **80.67%**

**Decision Tree Classifier**
Accuracy: 79.53%

**Model Tuning:**

**GridSearchCV was applied to fine-tune hyperparameters for Decision Tree.
Best Accuracy after tuning: 81.45%**

best_params_ from GridSearchCV were used for final model refinement.

**âš™ï¸ Technologies Used
Python 3**

NumPy, Pandas

Scikit-learn

Matplotlib, Seaborn (for visualization)

Jupyter Notebook

**ğŸ§ª Results**
Model	Accuracy (%)
Random Forest	80.67
Decision Tree (default)	79.53
Decision Tree (tuned)	81.45

**ğŸ” Key Learnings**
  - Importance of feature encoding for tree-based models.

  - Value of hyperparameter tuning using GridSearchCV to enhance model performance.

  - Comparative evaluation between ensemble and single-tree methods.

ğŸ“¬ Contact
For inquiries or collaboration opportunities:
**Lavit Thapa** â€“ LinkedIn - https://www.linkedin.com/in/lavit-thapa/

